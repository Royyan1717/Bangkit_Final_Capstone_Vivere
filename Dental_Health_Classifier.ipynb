{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Dental Health Classifier.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "mount_file_id": "11V-RXK4Oe6dJxSHIAU8qV4rcDnfMYMGW",
      "authorship_tag": "ABX9TyM4ApfpaJPjSLEbBa639kok",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ValensioLeonard/Bangkit_Final_Capstone_Vivere/blob/main/Dental_Health_Classifier.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8uX_cvQrc-nK"
      },
      "source": [
        "# Dental Health Classifier, Bangkit Final Capstone"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4u9AQ-gOc706"
      },
      "source": [
        "import numpy as np\n",
        "import os\n",
        "import tensorflow as tf\n",
        "import matplotlib.pyplot as plt\n",
        "from tqdm import tqdm\n",
        "from shutil import copyfile\n",
        "import re\n",
        "from shutil import move\n",
        "\n",
        "\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sHK0HKPFdKTF",
        "outputId": "d9b6644a-f6ed-4828-c2a4-4c6d406bbecf"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/gdrive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ICvjgU88da3q",
        "outputId": "3638bbba-ae0e-4818-f345-9fd11a3a78f9"
      },
      "source": [
        "%cd '/content/gdrive/MyDrive/Bangkit Final Project Files'"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/gdrive/MyDrive/Bangkit Final Project Files\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rQrKES5afehj"
      },
      "source": [
        "## Generate Dataset Folder"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QyINWCJZfYPd"
      },
      "source": [
        "# Define our directories and files\n",
        "train_dir = 'Dataset/Training/'\n",
        "validation_dir = 'Dataset/Validation/'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vqEC66A2gWh7",
        "outputId": "a2dcd085-8296-4061-ad55-bc406dde6441"
      },
      "source": [
        "# Use Temporary dir\n",
        "\n",
        "# Populate Temporary Directory\n",
        "def copy_file(source, destination):\n",
        "  list_to_copy = os.listdir(source)\n",
        "  for member in tqdm(list_to_copy):\n",
        "    source_file = os.path.join(source, member)\n",
        "    dest_file = os.path.join(destination, member)\n",
        "    copyfile(source_file, dest_file)\n",
        "\n",
        "copy_file(train_dir, 'Dataset/Dataset2/Training')\n",
        "copy_file(validation_dir, 'Dataset/Dataset2/Validation')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 113/113 [01:52<00:00,  1.00it/s]\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OCVqP3pjmiFq"
      },
      "source": [
        "# Update Training and Validation Dir\n",
        "\n",
        "train_dir = 'Dataset/Dataset2/Training'\n",
        "validation_dir = 'Dataset/Dataset2/Validation'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HeWY9K81pIGT"
      },
      "source": [
        "## Move file to appropriate folder"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "F8kCMPNImbTx",
        "outputId": "8f738dbe-4d87-46cc-9f98-0713f16d9208"
      },
      "source": [
        "def move_to_class(dir):\n",
        "  files = os.listdir(dir)\n",
        "  for file in files:\n",
        "    source_file = os.path.join(dir, file)\n",
        "    try:\n",
        "      if re.findall(r'^(.+)\\.[0-9]+', file)[0] == 'no':\n",
        "        dest_file = os.path.join(dir, 'Healthy' ,file)\n",
        "        move(source_file, dest_file)\n",
        "      else:\n",
        "        dest_file = os.path.join(dir, 'Caries' ,file)\n",
        "        move(source_file, dest_file)\n",
        "    except:\n",
        "      print('Skipped: ' + file)\n",
        "\n",
        "move_to_class(train_dir)\n",
        "move_to_class(validation_dir)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Skipped: Caries\n",
            "Skipped: Healthy (1)\n",
            "Skipped: Caries\n",
            "Skipped: Healthy\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ieeykfX3pLvY"
      },
      "source": [
        "## Convert file format to PNG"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LRIE6CjUpLMQ"
      },
      "source": [
        "from PIL import Image\n",
        "import os\n",
        "\n",
        "def convert_to_png(dir, verbose = False, remove_former = False):\n",
        "  for file in os.listdir(dir):\n",
        "    if file.endswith(\".png\") == False:\n",
        "        im = Image.open(os.path.join(dir, file))\n",
        "        name = re.findall(r'(.+)\\.[\\w+]+', file)[0] + '.png'        \n",
        "        rgb_im = im.convert('RGB')\n",
        "        rgb_im.save(os.path.join(dir, name))\n",
        "\n",
        "        if remove_former:\n",
        "          os.remove(os.path.join(dir, file))\n",
        "\n",
        "        if verbose:\n",
        "          print('converted ' + file + ' to ' + name)\n",
        "        continue\n",
        "    else:\n",
        "        continue"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xHceEDq2rheW"
      },
      "source": [
        "convert_to_png(os.path.join(train_dir, 'Healthy'), verbose = True, remove_former = True)\n",
        "convert_to_png(os.path.join(train_dir, 'Caries'),  remove_former = True)\n",
        "convert_to_png(os.path.join(validation_dir, 'Healthy'),  remove_former = True)\n",
        "convert_to_png(os.path.join(validation_dir, 'Caries'),  remove_former = True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W4ASjY4VfZGY"
      },
      "source": [
        "## Initiate Image Generator"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7u5hSBWHeU3j",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "77a7f0d5-d11c-45f1-850c-620a484e4096"
      },
      "source": [
        "train_heathy_dir = os.path.join(train_dir, 'Healthy')\n",
        "train_caries_dir = os.path.join(train_dir, 'Caries')\n",
        "validation_healthy_dir = os.path.join(validation_dir, 'Healthy')\n",
        "validation_caries_dir = os.path.join(validation_dir, 'Caries')\n",
        "\n",
        "train_heathy_fnames = os.listdir(train_heathy_dir)\n",
        "train_caries_fnames = os.listdir(train_caries_dir)\n",
        "validation_healthy_fnames = os.listdir(validation_healthy_dir)\n",
        "validation_caries_fnames = os.listdir(validation_caries_dir)\n",
        "\n",
        "print(len(train_heathy_fnames))\n",
        "print(len(train_caries_fnames))\n",
        "print(len(validation_healthy_fnames))\n",
        "print(len(validation_caries_fnames))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "56\n",
            "57\n",
            "24\n",
            "24\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BqL7rnTKeT1J",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1e7858f0-34d2-46e1-8e8f-3feb7805f66a"
      },
      "source": [
        "# Add our data-augmentation parameters to ImageDataGenerator\n",
        "train_datagen = tf.keras.preprocessing.image.ImageDataGenerator(rescale = 1./255.,\n",
        "                                   zoom_range = 0.2,\n",
        "                                   shear_range = 0.2,\n",
        "                                   rotation_range = 40,\n",
        "                                   width_shift_range = 0.2,\n",
        "                                   height_shift_range = 0.2,\n",
        "                                   horizontal_flip = True)\n",
        "\n",
        "# Note that the validation data should not be augmented!\n",
        "test_datagen = ImageDataGenerator(rescale = 1./255.)\n",
        "\n",
        "# Flow training images in batches of 20 using train_datagen generator\n",
        "train_generator = train_datagen.flow_from_directory(train_dir,\n",
        "                                                    class_mode = 'binary',\n",
        "                                                    batch_size = 10,\n",
        "                                                    target_size = (150, 150))     \n",
        "\n",
        "# Flow validation images in batches of 20 using test_datagen generator\n",
        "validation_generator =  test_datagen.flow_from_directory(validation_dir,\n",
        "                                                    class_mode = 'binary',\n",
        "                                                    batch_size = 10,\n",
        "                                                    target_size = (150, 150))\n",
        "\n",
        "# Expected Output:\n",
        "# Found 113 images belonging to 2 classes.\n",
        "# Found 48 images belonging to 2 classes."
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 113 images belonging to 2 classes.\n",
            "Found 48 images belonging to 2 classes.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZLkjWcIbeT61"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}